<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="NovelHopQA Benchmark" />
    <meta name="author" content="" />
    <link rel="icon" type="image/png" href="logo/novelhopqa.png" />
    <title>NovelHopQA</title>

    <!-- Bootstrap core CSS -->
    <link href="./style/bootstrap.min.css" rel="stylesheet" />

    <!-- Custom fonts for this template -->
    <link
      href="./style/font-awesome.min.css"
      rel="stylesheet"
      type="text/css"
    />
    <link
      rel="stylesheet"
      href="./style/all.css"
      integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU"
      crossorigin="anonymous"
    />

    <!-- Custom styles for this template -->
    <link href="./style/clean-blog.min.css" rel="stylesheet" />
    <link href="./style/bird.css" rel="stylesheet" />
  </head>

  <body>
    <header class="masthead" id="header-color">
      <div style="background-color: #485159; text-align: left">
        <img
          style="margin-top: 2px; padding: 8px"
          height="70px"
          src="./logo/algoverse_logo_higher_quality-removebg-preview.png"
          alt="Algoverse Logo"
        />
        <img
          style="margin-top: 2px; padding: 8px"
          height="70px"
          src="./logo/Seal_of_University_of_California__Berkeley.svg-removebg-preview.png"
          alt="UC Berkeley Logo"
        />
        <img
          style="margin-top: 2px; padding: 8px; margin-left: -8px;"
          height="70px"
          src="./logo/bmc-removebg-preview.png"
          alt="BMC Logo"
        />
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-10 col-md-12 mx-auto">
            <div class="row site-heading flex-box">
              <div class="col-lg-3">
                <img id="logo-img" src="logo/novelhopqa.png" alt="logo" style="max-height: 230px; margin-left: 50px;" />
              </div>
              <div class="col-lg-9">
                <div class="align-middle">
                  <h1 id="bird-title" style="color: #A0522D;">NovelHopQA</h1>
                  <span class="subheading" id="caption">Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    <!-- Main Content -->
    <div class="container" id="main">
      <div class="row">
        <div class="col-lg-5">
          <div class="list-group">
            <div class="list-group-item" id="introduction">
              <h4>About NovelHopQA</h4>
              <p>
  NovelHopQA is a large-scale benchmark designed to test how language models handle multi-step reasoning over long passages from real novels. With 4,000 questions spanning 64k‚Äì128k-token excerpts and up to 4 reasoning hops, it reveals that even top models struggle as tasks get longer and more complex. NovelHopQA highlights key challenges in deep comprehension and multi-hop inference, providing a valuable tool for improving future language models.
</p>
              <div id="button-group" style="display: flex; flex-direction: column; gap: 16px; align-items: stretch; margin-top: 24px;">
                <a href="https://arxiv.org/pdf/2506.02000" target="_blank" style="width: 100%;">
                  <button type="button" class="btn btn-a" style="width: 100%; font-size: 1.15em;">üìÑ Paper</button>
                </a>
                <a href="coming soon" target="_blank" style="width: 100%;">
                  <button type="button" class="btn btn-b" style="width: 100%; font-size: 1.15em;">üíª Code</button>
                </a>
                <a href="https://huggingface.co/datasets/abhaygupta1266/novelhopqa" target="_blank" style="width: 100%;">
                  <button type="button" class="btn btn-d" style="width: 100%; font-size: 1.15em;">üî• Dataset</button>
                </a>
                </div>
            </div>
            <style>
              .scroll-container {
                position: relative;
                width: 100%;
                max-height: 300px;
                overflow-y: scroll;
              }

              /* Hide the scrollbar by default */
              .scroll-container::-webkit-scrollbar {
                width: 10px;
                background: transparent;
              }

              /* Set the scrollbar thumb color */
              .scroll-container::-webkit-scrollbar-thumb {
                background-color: #ffffff;
                border-radius: 5px;
              }

              /* Show the scrollbar when the mouse is hovering over the scroll container */
              .scroll-container:hover::-webkit-scrollbar {
                width: 10px;
              }

              .scroll-container:hover::-webkit-scrollbar-thumb:hover {
                background-color: #555;
              }
            </style>

            <div class="list-group-item" id="overview">
              <h4>Key Findings &amp; Impact</h4>
              <div class="scroll-container">
                <div class="card card-outline-secondary mb-4" style="text-align: left">
                  <div class="card-body" style="background-color: #f1f6f9">
                    <h5 style="color: #A0522D;">Paper Overview</h5>
                    <div style="text-align:center; margin: 2em 0 2.5em 0;">
                      <img src="logo/Untitled_drawing_5-1.png" alt="Simplified Methodology Diagram" style="max-width: 95%; height: auto; border-radius: 12px; box-shadow: 0 4px 16px rgba(80,80,80,0.06); border: 1px solid #e0e0e0;">
                      <div style="font-size: 1.05em; color: #555; margin-top: 0.7em; font-style: italic;">
                        <strong>Figure:</strong> <span style="color:#A0522D;">Simplified Methodology.</span> NovelHopQA constructs multi-hop QA chains by extracting high-frequency keywords from novels, filtering paragraphs, and incrementally building reasoning paths (hops) that culminate in challenging question‚Äìanswer pairs. Each hop integrates more context, enabling deeper reasoning.
                      </div>
                    </div>
                    <p style="margin-bottom: 15px;">NovelHopQA is the first benchmark to jointly vary both hop depth (1-4 hops) and context length (64k-128k tokens) in natural narrative settings. Current large language models (LLMs) struggle to answer questions that span tens of thousands of tokens, especially when multi-hop reasoning is involved. While prior benchmarks explore long-context comprehension or multi-hop reasoning in isolation, none jointly vary context length and reasoning depth in natural narrative settings. When crucial evidence is buried in the middle of a long context, accuracy can plunge by more than 20 points <a href="https://arxiv.org/abs/2307.03172" target="_blank">(Liu et al., 2023)</a>. Even frontier models score below 50% exact match on multi-document suites, showing that larger context windows alone cannot solve cross-document reasoning.</p>

                    <h5 style="color: #A0522D; margin-top: 20px;">Related Work</h5>
                    <p>Multi-hop benchmarks fall into two groups:</p>
                    <ul style="padding-left: 20px;">
                      <li><strong>Multi-hop reasoning:</strong> WikiHop <a href="https://arxiv.org/abs/1710.06481" target="_blank">(Welbl et al., 2018)</a> and HotpotQA <a href="https://arxiv.org/abs/1809.09600" target="_blank">(Yang et al., 2018)</a> probe two-hop reasoning over short Wikipedia passages. These datasets catalyzed advances in multi-hop inference but restrict inputs to at most a few thousand tokens.</li>
                      <li><strong>Long context:</strong> NarrativeQA <a href="https://arxiv.org/abs/1712.07040" target="_blank">(Kocisk√Ω et al., 2017)</a>, QuALITY <a href="https://arxiv.org/abs/2112.08608" target="_blank">(Pang et al., 2022)</a>, and NovelQA <a href="https://arxiv.org/abs/2403.12766" target="_blank">(Wang et al., 2024)</a> embrace longer inputs but focus on single-hop or summary questions. Standardized long-context suites like LongBench <a href="https://arxiv.org/abs/2308.14508" target="_blank">(Bai et al., 2024)</a> and LEval <a href="https://arxiv.org/abs/2307.11088" target="_blank">(An et al., 2023)</a> show that models use a fraction of their window sizes while keeping hop depth fixed.</li>
                    </ul>
                    <p>NovelHopQA fills this gap by simultaneously testing reasoning depth and long-context comprehension in coherent narratives.</p>

                    <h5 style="color: #A0522D; margin-top: 20px;">Benchmark Features</h5>
                    <ul style="padding-left: 20px;">
                      <li>4,000 multi-hop QA examples from 83 full-length public-domain novels</li>
                      <li>Context windows ranging from 64k to 128k tokens</li>
                      <li>Questions require integrating 1‚Äì4 reasoning hops across narrative chains</li>
                      <li>Human validation ensures high alignment (>6.5/7) and hop-match accuracy (>94%)</li>
                    </ul>

                    <h5 style="color: #A0522D; margin-top: 20px;">Methodology</h5>
                    <p>We build NovelHopQA through a four-stage pipeline:</p>
                    <ol style="padding-left: 20px;">
                      <li><strong>Novel Selection:</strong> We selected 83 English novels from Project Gutenberg, spanning mystery, adventure, romance, and literary classics, including both first- and third-person narration.</li>
                      <li><strong>Anchor-Keyword Discovery:</strong> For each novel, we prompted GPT-4o-mini to suggest five "anchor" keywords‚Äîcharacters, locations, or objects central to the plot. If any keyword appears fewer than 50 times in the text, we discard and re-sample.</li>
                      <li><strong>Paragraph Chaining & QA Generation:</strong> We implemented a keyword-guided process that:
                        <ul style="padding-left: 20px; margin-top: 5px;">
                          <li>Selects paragraphs containing specific keywords</li>
                          <li>Extracts new related keywords for subsequent hops</li>
                          <li>Chains paragraphs with increasing hop depth (1-4)</li>
                          <li>Regenerates QA pairs at each step to integrate new evidence</li>
                        </ul>
                      </li>
                      <li><strong>QA Validation:</strong> We filter examples using model and human validation to ensure answerability and correct hop depth. Ten human annotators confirmed high alignment (>6.5/7) and hop-match accuracy (>94%).</li>
                    </ol>

                    <h5 style="color: #A0522D; margin-top: 20px;">Results</h5>
                    <p>We evaluated six state-of-the-art models: o1, GPT-4o, GPT-4o-mini, Gemini 2.5 Pro, Gemini 2.0 Flash, and Gemini 2.0 Flash Lite. Key findings:</p>
                    <ul style="padding-left: 20px;">
                      <li><strong>Impact of hop depth:</strong> All models exhibit consistent performance degradation as hop depth increases. On average, accuracy drops roughly 12 points from 1-hop to 4-hop at 64k context length.</li>
                      <li><strong>Impact of context length:</strong> Longer contexts also lead to reduced accuracy, though the effect is milder than that of hop count. Across models, 1-hop performance drops about 5 points when moving from 64k to 128k contexts.</li>
                      <li><strong>No model maintains strong performance on the hardest tasks (4-hop at 128k)</strong>, where even top models dip below 80% accuracy.</li>
                    </ul>
                    

                  </div>
                </div>
              </div>
            </div>
            <div class="list-group-item" id="team">
              <h4>NovelHopQA Team</h4>
<div class="row">
  <div class="col-md-12">
    <p style="margin-bottom: 15px;">
      NovelHopQA is developed by researchers at Algoverse AI Research:
    </p>
    <ul style="padding-left: 20px;">
      <li><a href="https://www.linkedin.com/in/abhaygupta12/" target="_blank">Abhay Gupta (Lead Author)</a></li>
      <li><a href="https://www.linkedin.com/in/m1chae11u/" target="_blank">Michael Lu (Lead Investigator)</a></li>
      <li><a href="https://www.linkedin.com/in/zhu-kevin1/" target="_blank">Kevin Zhu (Senior Author)</a></li>
      <li><a href="https://www.linkedin.com/in/sean-obrien-research/" target="_blank">Sean O'Brien (Senior Author)</a></li>
      <li><a href="https://www.linkedin.com/in/vasu-sharma-6b460592/" target="_blank">Vasu Sharma (Senior Author)</a></li>
    </ul>
  </div>
</div>
            </div>
            
            <div class="list-group-item" id="contact">
              <h4>Contact</h4>
              <div class="row">
                <div class="col-md-12">
                  <p>
                    For questions about the benchmark, collaboration opportunities, or to report issues, please contact us at:
                    <code>abhaygupta1266@gmail.com</code>
                  </p>
                  <p>
                    We welcome contributions and feedback from the research community to help improve model fairness across diverse English dialects.
                  </p>
                </div>
              </div>
            </div>
            
            <div class="list-group-item" id="citation-section">
              <h4>Citation</h4>
              <pre id="citation">
@misc{gupta2025novelhopqadiagnosingmultihopreasoning,
      title={NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts}, 
      author={Abhay Gupta and Michael Lu and Kevin Zhu and Sean O'Brien and Vasu Sharma},
      year={2025},
      eprint={2506.02000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.02000}
}</pre>
            </div>
          </div>
        </div>

        <div class="col-lg-7">
          <div class="card card-outline-secondary">
            <div class="card-header">
              <ul class="nav nav-tabs card-header-tabs" id="leaderboard-tabs">
                <li class="nav-item">
                  <a class="nav-link active" id="accuracy-tab" href="javascript:void(0)" onclick="showTab('accuracy-content')">Leaderboard</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" id="paper-tab" href="javascript:void(0)" onclick="showTab('paper-content')">Paper Overview</a>
                </li>
              </ul>

            </div>
            <div class="tab-content" id="leaderboardTabContent">
              <div class="tab-pane fade show active" id="accuracy-content" role="tabpanel" aria-labelledby="accuracy-tab">
                <div class="table-wrapper" style="overflow-x: visible; width: 900px; margin: 0 auto;">
  <p style="margin-top: 1em; margin-bottom: 1em;">
This table reports the accuracy (%) of six language models on the NovelHopQA benchmark, grouped by context length (64k, 96k, 128k tokens) and reasoning hop count (1‚Äì4). For each group, the highest model accuracy is bolded. Results show that all models experience accuracy drops as context length and hop count increase, revealing the challenge of multi-hop reasoning over long narratives.
</p>
  <table class="table table-striped table-bordered" id="accuracy-table" style="font-size: 0.9em; width: 100%;">
    <thead class="thead-light">
      <tr>
        <th rowspan="2" class="align-middle text-center">Context</th>
        <th rowspan="2" class="align-middle text-center">Hop</th>
        <th class="text-center">ü•á Gemini 2.5 P</th>
        <th class="text-center">ü•à o1</th>
        <th class="text-center">ü•â 4o</th>
        <th class="text-center">Gemini 2.0 F</th>
        <th class="text-center">Gemini 2.0 FL</th>
        <th class="text-center">4o-mini</th>
        <th class="text-center">Avg.</th>
      </tr>
    </thead>
    <tbody>
      <!-- 64k -->
      <tr><td rowspan="4" class="align-middle text-center">64k</td><td class="text-center">1</td><td class="text-center"><b>92.34</b></td><td class="text-center">92.51</td><td class="text-center">90.12</td><td class="text-center">87.37</td><td class="text-center">82.53</td><td class="text-center">75.49</td><td class="text-center">86.73</td></tr>
      <tr><td class="text-center">2</td><td class="text-center"><b>87.84</b></td><td class="text-center">87.66</td><td class="text-center">84.25</td><td class="text-center">77.02</td><td class="text-center">71.39</td><td class="text-center">74.77</td><td class="text-center">80.48</td></tr>
      <tr><td class="text-center">3</td><td class="text-center"><b>85.12</b></td><td class="text-center">84.99</td><td class="text-center">81.34</td><td class="text-center">74.25</td><td class="text-center">70.05</td><td class="text-center">73.14</td><td class="text-center">78.13</td></tr>
      <tr><td class="text-center">4</td><td class="text-center"><b>82.45</b></td><td class="text-center">82.15</td><td class="text-center">78.47</td><td class="text-center">71.76</td><td class="text-center">65.33</td><td class="text-center">68.04</td><td class="text-center">74.69</td></tr>
      <!-- 96k -->
      <tr><td rowspan="4" class="align-middle text-center">96k</td><td class="text-center">1</td><td class="text-center">90.12</td><td class="text-center"><b>90.35</b></td><td class="text-center">88.83</td><td class="text-center">82.26</td><td class="text-center">78.44</td><td class="text-center">72.25</td><td class="text-center">83.71</td></tr>
      <tr><td class="text-center">2</td><td class="text-center"><b>86.03</b></td><td class="text-center">85.88</td><td class="text-center">82.67</td><td class="text-center">74.02</td><td class="text-center">67.04</td><td class="text-center">67.44</td><td class="text-center">77.18</td></tr>
      <tr><td class="text-center">3</td><td class="text-center"><b>83.71</b></td><td class="text-center">83.41</td><td class="text-center">80.41</td><td class="text-center">73.38</td><td class="text-center">66.05</td><td class="text-center">66.97</td><td class="text-center">75.66</td></tr>
      <tr><td class="text-center">4</td><td class="text-center"><b>80.98</b></td><td class="text-center">80.68</td><td class="text-center">76.92</td><td class="text-center">70.26</td><td class="text-center">62.81</td><td class="text-center">65.59</td><td class="text-center">72.87</td></tr>
      <!-- 128k -->
      <tr><td rowspan="4" class="align-middle text-center">128k</td><td class="text-center">1</td><td class="text-center"><b>89.10</b></td><td class="text-center">88.76</td><td class="text-center">86.95</td><td class="text-center">81.77</td><td class="text-center">75.31</td><td class="text-center">70.03</td><td class="text-center">81.99</td></tr>
      <tr><td class="text-center">2</td><td class="text-center"><b>84.70</b></td><td class="text-center">84.33</td><td class="text-center">80.52</td><td class="text-center">69.13</td><td class="text-center">62.21</td><td class="text-center">63.95</td><td class="text-center">74.14</td></tr>
      <tr><td class="text-center">3</td><td class="text-center"><b>82.20</b></td><td class="text-center">81.92</td><td class="text-center">78.03</td><td class="text-center">68.78</td><td class="text-center">62.07</td><td class="text-center">62.95</td><td class="text-center">72.66</td></tr>
      <tr><td class="text-center">4</td><td class="text-center">78.55</td><td class="text-center"><b>78.80</b></td><td class="text-center">74.64</td><td class="text-center">67.32</td><td class="text-center">57.39</td><td class="text-center">61.18</td><td class="text-center">69.65</td></tr>
    </tbody>
  </table>
</div>

                <h5 style="color: #A0522D; margin-top: 40px; font-size: 1.4rem; text-align: center;">Performance Visualizations</h5>
                <p style="margin-bottom: 1.5em; font-size: 1.05rem; text-align: center;">The following graphs visualize model performance across different hop depths and context lengths, clearly showing the consistent accuracy drops as both factors increase.</p>
                
                <div class="container-fluid px-0 mb-5">
                  <div class="row justify-content-center">
                    <div class="col-12 mb-4">
                      <div class="card shadow-sm border-0" style="background-color: #f8f9fa;">
                        <div class="card-header text-center" style="background-color: #f1f6f9; border-bottom: 2px solid #A0522D; font-weight: 600; font-size: 1.2rem; padding: 12px;">Model Performance Across Hop Depths</div>
                        <div class="card-body p-4">
                          <!-- Larger single graph view -->
                          <div class="row mb-4">
                            <div class="col-lg-10 offset-lg-1">
                              <div class="card shadow-sm mb-4">
                                <div class="card-header text-center" style="background-color: #f8f9fa; font-weight: 500; font-size: 1.1rem;">64k Tokens</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/0e0192ec-a880-4fef-b4ae-1c74a0f8b979 (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/0e0192ec-a880-4fef-b4ae-1c74a0f8b979 (1).png" alt="Model Performance @ 64k Tokens" class="img-fluid" style="width: 100%; max-height: 450px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                          </div>
                          
                          <!-- Two smaller graphs in a row -->
                          <div class="row">
                            <div class="col-md-6 mb-3">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f8f9fa; font-weight: 500; font-size: 1.1rem;">96k Tokens</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/5df64999-94ae-4d98-8d57-f871c9c47333 (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/5df64999-94ae-4d98-8d57-f871c9c47333 (1).png" alt="Model Performance @ 96k Tokens" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                            <div class="col-md-6 mb-3">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f8f9fa; font-weight: 500; font-size: 1.1rem;">128k Tokens</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/69281487-97ee-4580-94b7-84f857c1bbdb (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/69281487-97ee-4580-94b7-84f857c1bbdb (1).png" alt="Model Performance @ 128k Tokens" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                          </div>
                          <p class="text-center mt-4 mb-1" style="font-size: 1.05rem; font-style: italic; color: #555;">These visualizations demonstrate that even top-performing models experience significant performance degradation as reasoning depth increases, especially at longer context lengths.</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
                
                <!-- Second set of graphs: Model Performance Across Context Lengths -->
                <h6 style="color: #A0522D; margin-top: 30px; font-size: 1.3rem; text-align: center;">Model Performance Across Context Lengths</h6>
                <p style="margin-bottom: 1.5em; font-size: 1.05rem; text-align: center;">These graphs show how model accuracy changes with increasing context length for each hop level, highlighting the combined challenge of long contexts and multi-hop reasoning.</p>
                
                <div class="container-fluid px-0 mb-5">
                  <div class="row justify-content-center">
                    <div class="col-12 mb-4">
                      <div class="card shadow-sm border-0" style="background-color: #f8f9fa;">
                        <div class="card-body p-4">
                          <div class="row">
                            <div class="col-md-6 mb-4">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f1f6f9; border-bottom: 2px solid #A0522D; font-weight: 500; font-size: 1.1rem;">Hop Level 1</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/1af1f5d4-5b8a-44a5-8ffc-4db97f33e2bb (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/1af1f5d4-5b8a-44a5-8ffc-4db97f33e2bb (1).png" alt="Model Performance Across Context Lengths @ Hop Level 1" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                            <div class="col-md-6 mb-4">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f1f6f9; border-bottom: 2px solid #A0522D; font-weight: 500; font-size: 1.1rem;">Hop Level 2</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/99789369-3849-4a8e-8296-1da806c58d7e (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/99789369-3849-4a8e-8296-1da806c58d7e (1).png" alt="Model Performance Across Context Lengths @ Hop Level 2" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                            <div class="col-md-6 mb-4">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f1f6f9; border-bottom: 2px solid #A0522D; font-weight: 500; font-size: 1.1rem;">Hop Level 3</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/bd71019a-3e7c-4573-8700-028af04f019c (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/bd71019a-3e7c-4573-8700-028af04f019c (1).png" alt="Model Performance Across Context Lengths @ Hop Level 3" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                            <div class="col-md-6 mb-4">
                              <div class="card h-100 shadow-sm">
                                <div class="card-header text-center" style="background-color: #f1f6f9; border-bottom: 2px solid #A0522D; font-weight: 500; font-size: 1.1rem;">Hop Level 4</div>
                                <div class="card-body text-center p-0">
                                  <a href="logo/97d1ff7a-0cf3-4dca-bb66-70a9c8c47209 (1).png" target="_blank" title="Click to view full size">
                                    <img src="logo/97d1ff7a-0cf3-4dca-bb66-70a9c8c47209 (1).png" alt="Model Performance Across Context Lengths @ Hop Level 4" class="img-fluid" style="width: 100%; min-height: 300px; object-fit: contain; border-radius: 0 0 8px 8px;">
                                  </a>
                                </div>
                              </div>
                            </div>
                          </div>
                          <p class="text-center mt-3 mb-0" style="font-size: 1.05rem; font-style: italic; color: #555;">These graphs reveal that while context length affects performance, the impact is more pronounced at higher hop levels, suggesting that reasoning complexity is a stronger factor in model performance degradation than just context length alone.</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <div class="tab-pane fade" id="paper-content" role="tabpanel" aria-labelledby="paper-tab">
                <div class="p-4">
                  <h4 class="mb-4">NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts</h4>
                  <div>
  <h5 style="color: #A0522D;">Paper Overview</h5>
  <p><strong>NovelHopQA</strong> is the first benchmark to jointly vary both hop depth (1‚Äì4 hops) and context length (64k‚Äì128k tokens) in natural narrative settings. Current large language models (LLMs) struggle to answer questions that span tens of thousands of tokens, especially when multi-hop reasoning is involved. Prior benchmarks explore long-context comprehension or multi-hop reasoning in isolation, but none jointly vary context length and reasoning depth in natural narrative settings. When crucial evidence is buried in the middle of a long context, accuracy can plunge by more than 20 points <a href="https://arxiv.org/abs/2307.03172" target="_blank">(Liu et al., 2023)</a>. Even frontier models score below 50% exact match on multi-document suites, showing that larger context windows alone cannot solve cross-document reasoning.</p>

  <h5 style="color: #A0522D; margin-top: 20px;">Related Work</h5>
<p>NovelHopQA builds upon and extends several foundational directions in long-context and multi-hop question answering:</p>
<ul style="padding-left: 20px;">
  <li><strong>WikiHop &amp; HotpotQA: Early Multi-Hop Reasoning</strong> (<a href="https://arxiv.org/abs/1710.06481" target="_blank">Welbl et al., 2018</a>; <a href="https://arxiv.org/abs/1809.09600" target="_blank">Yang et al., 2018</a>): Pioneered multi-hop QA over short Wikipedia passages, catalyzing advances in compositional reasoning but limited to short contexts.</li>
  <li><strong>NarrativeQA, QuALITY, NovelQA, NoCha: Long-Context Comprehension</strong> (<a href="https://arxiv.org/abs/1712.07040" target="_blank">Kocisk√Ω et al., 2017</a>; <a href="https://arxiv.org/abs/2112.08608" target="_blank">Pang et al., 2022</a>; <a href="https://arxiv.org/abs/2403.12766" target="_blank">Wang et al., 2024a</a>; <a href="https://arxiv.org/abs/2406.16264" target="_blank">Karpinska et al., 2024</a>): Benchmarks using book- or script-length narratives, focusing on single-hop or summary questions, with NovelQA and NoCha raising the ceiling to 200k tokens and including some multi-hop items.</li>
  <li><strong>MuSiQue &amp; BABILong: Synthetic Stress Tests</strong> (<a href="https://arxiv.org/abs/2108.00573" target="_blank">Trivedi et al., 2022</a>; <a href="https://arxiv.org/abs/2406.10149" target="_blank">Kuratov et al., 2024</a>): Introduce compositional and multi-hop questions using synthetic or stitched contexts, probing model brittleness at scale.</li>
  <li><strong>LongBench, LEval, RULER, Marathon: Standardized Long-Context Evaluation</strong> (<a href="https://arxiv.org/abs/2308.14508" target="_blank">Bai et al., 2024</a>; <a href="https://arxiv.org/abs/2307.11088" target="_blank">An et al., 2023</a>; <a href="https://arxiv.org/abs/2404.06654" target="_blank">Hsieh et al., 2024</a>; <a href="https://arxiv.org/abs/2312.09542" target="_blank">Zhang et al., 2024</a>): Evaluate LLMs on tasks with large context windows, but typically keep reasoning depth fixed.</li>
  <li><strong>FanOutQA &amp; Loong: Multi-Document and Breadth-Oriented QA</strong> (<a href="https://arxiv.org/abs/2402.14116" target="_blank">Zhu et al., 2024</a>; <a href="https://arxiv.org/abs/2406.17419" target="_blank">Wang et al., 2024b</a>): Assess cross-document and multi-hop reasoning over multiple Wikipedia pages or diverse domains, with FanOutQA focusing on breadth and Loong on domain diversity.</li>
  <li><strong>LooGLE &amp; LV-Eval: Robustness and Length Control</strong> (<a href="https://arxiv.org/abs/2311.04939" target="_blank">Li et al., 2024a</a>; <a href="https://arxiv.org/abs/2402.05136" target="_blank">Yuan et al., 2024</a>): Control for training-data leakage, add misleading facts, and test robustness across length bands up to 256k tokens.</li>
  <li><strong>Architectural Advances: Longformer, BigBird, Transformer-XL, LongRoPE</strong> (<a href="https://arxiv.org/abs/2004.05150" target="_blank">Beltagy et al., 2020</a>; <a href="https://arxiv.org/abs/2007.14062" target="_blank">Zaheer et al., 2021</a>; <a href="https://arxiv.org/abs/1901.02860" target="_blank">Dai et al., 2019</a>; <a href="https://arxiv.org/abs/2402.13753" target="_blank">Ding et al., 2024</a>): Enable LLMs to process tens or hundreds of thousands of tokens using sparse attention, recurrence, and advanced positional encodings.</li>
  <li><strong>Retrieval-Augmented and Memory Approaches</strong> (<a href="https://arxiv.org/abs/2005.11401" target="_blank">Lewis et al., 2021</a>; <a href="https://arxiv.org/abs/2203.08913" target="_blank">Wu et al., 2022</a>; <a href="https://arxiv.org/abs/2310.03025" target="_blank">Xu et al., 2024</a>; <a href="https://arxiv.org/abs/2408.03246" target="_blank">Li et al., 2024c</a>): Improve long-context QA by combining retrieval and external memory with LLMs, outperforming context-only baselines at scale.</li>
  <li><strong>Failure Mode Analyses: Lost in the Middle, NeedleBench</strong> (<a href="https://arxiv.org/abs/2307.03172" target="_blank">Liu et al., 2023a,b</a>; <a href="https://arxiv.org/abs/2407.11963" target="_blank">Li et al., 2024b</a>): Reveal that even with large windows, models struggle with positional and retrieval brittleness, especially when evidence is scattered.</li>
</ul>
<p>NovelHopQA is the first benchmark to jointly vary both context length and reasoning depth in natural narrative settings, providing a controlled diagnostic for multi-hop reasoning at scale.</p>

  <h5 style="color: #A0522D; margin-top: 20px;">Benchmark Features</h5>
  <div class="table-responsive mb-3">
    <table class="table table-bordered table-sm">
      <thead class="thead-light">
        <tr>
          <th>Feature</th>
          <th>Details</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>Number of QA examples</td><td>4,000</td></tr>
        <tr><td>Source novels</td><td>83 (Project Gutenberg)</td></tr>
        <tr><td>Context window sizes</td><td>64k, 128k tokens</td></tr>
        <tr><td>Reasoning hops</td><td>1‚Äì4</td></tr>
        <tr><td>Human validation</td><td>&gt;6.5/7 alignment, &gt;94% hop-match accuracy</td></tr>
      </tbody>
    </table>


  <h5 style="color: #A0522D; margin-top: 20px;">Methodology Pipeline</h5>
  <h6 style="color: #A0522D; margin-top: 18px; font-size: 1.1em;">Simplified Methodology</h6>
  <div style="text-align:center; margin: 1.5em 0 1.5em 0;">
    <img src="logo/Untitled_drawing_5-1.png" alt="Simplified Methodology Diagram" style="max-width: 95%; height: auto; border-radius: 12px; box-shadow: 0 4px 16px rgba(80,80,80,0.06); border: 1px solid #e0e0e0;">
    <div style="font-size: 1.05em; color: #555; margin-top: 0.7em; font-style: italic;">
      <strong>Figure:</strong> <span style="color:#A0522D;">Simplified Methodology.</span> NovelHopQA constructs multi-hop QA chains by extracting high-frequency keywords from novels, filtering paragraphs, and incrementally building reasoning paths (hops) that culminate in challenging question‚Äìanswer pairs. Each hop integrates more context, enabling deeper reasoning.
    </div>
  </div>
  <h6 style="color: #A0522D; margin-top: 22px; font-size: 1.1em;">Technical Pipeline Details</h6>
  <p style="margin-bottom: 0.7em;">
    For each book and hop depth <b>H</b> ‚àà {1, 2, 3, 4}, we assemble contexts and QA pairs as follows:
  </p>
  <ol style="padding-left: 22px;">
    <li><b>Hop 1:</b> Select a paragraph containing one of the book‚Äôs anchor keywords <b>k‚ÇÅ</b>. Prompt GPT-4o to generate a single-hop QA pair (<i>Q‚ÇÅ, A‚ÇÅ</i>) from this paragraph.</li>
    <li><b>Hops h ‚àà {2‚ÄìH}:</b>
      <ol type="a" style="padding-left: 18px;">
        <li>Extract a new keyword <b>k<sub>h</sub></b> from the context <b>C<sub>h-1</sub></b> using a related-keyword prompt.</li>
        <li>Sample a paragraph that contains both <b>k‚ÇÅ</b> and <b>k<sub>h</sub></b>, and append it to the growing context <b>C<sub>h</sub> = C<sub>h-1</sub> ‚à• new-paragraph</b>.</li>
        <li>Prompt GPT-4o to re-generate a single QA pair (<i>Q<sub>h</sub>, A<sub>h</sub></i>) over the full context <b>C<sub>h</sub></b>, ensuring the new QA integrates evidence from all <b>h</b> paragraphs.</li>
      </ol>
    </li>
    <li><b>Paragraph Exclusivity:</b> Remove each selected paragraph from the pool to prevent reuse. If no matching paragraph is found after seven attempts, abort the chain and restart with a fresh anchor.</li>
  </ol>
  <p style="margin-bottom: 1.2em;">
    This process matures each datapoint from (<i>C‚ÇÅ, Q‚ÇÅ, A‚ÇÅ</i>) through (<i>C<sub>H</sub>, Q<sub>H</sub>, A<sub>H</sub></i>), yielding coherent multi-hop QA examples grounded in authentic narrative context. Each 64k, 96k, or 128k window is sampled from a continuous span, with all hop paragraphs required to fall within it‚Äîensuring the QA chain reflects a cohesive narrative flow.
  </p>
  <p style="margin-bottom: 0.7em;"><b>Golden-Context Filtering:</b> To ensure answerability, all six models are evaluated on the original golden contexts used to generate each QA pair. Any question missed by any model is discarded, resulting in a dataset where all retained QA pairs are answerable by current leading models. This step ensures high dataset validity; detailed results are provided in the research paper.</p>
  <p style="margin-bottom: 1.2em;"><b>Irrelevant and No-Context Sanity Check:</b> To confirm that questions require actual reasoning and are not solvable by recall alone, 800 QA pairs (100 per hop) are tested under irrelevant and no-context conditions. Models perform poorly in these settings, indicating that correct answers depend on contextual grounding rather than memorization. This strengthens the benchmark's focus on true reasoning. Detailed results are provided in the research paper.</p>

  <h5 style="color: #A0522D; margin-top: 20px;">Human Validation Results</h5>
  <p style="margin-bottom: 1em;">
    The following table reports the average scores from 10 independent human annotators who evaluated the alignment and hop-match accuracy for each hop depth <b>H ‚àà {1, 2, 3, 4}</b>. Alignment is rated on a 1‚Äì7 Likert scale, and Hop Match measures the percentage of questions judged to require exactly <b>H</b> reasoning steps. High average alignment (&gt;6.5/7) and hop-match (&gt;94%) indicate strong dataset quality and clear multi-hop structure. These results demonstrate that the questions are both contextually grounded and require the intended number of reasoning steps.
  </p>
  <div class="table-responsive mb-3">
    <table class="table table-bordered table-sm">
      <thead class="thead-light">
        <tr>
          <th>Metric</th>
          <th>H = 1</th>
          <th>H = 2</th>
          <th>H = 3</th>
          <th>H = 4</th>
        </tr>
      </thead>
      <tbody>
        <tr><td><b>Alignment (1‚Äì7)</b></td><td>6.69</td><td>6.58</td><td>6.58</td><td>6.57</td></tr>
        <tr><td><b>Hop Match (%)</b></td><td>95.9</td><td>94.9</td><td>94.9</td><td>95.2</td></tr>
      </tbody>
    </table>
  </div>

  <h5 style="color: #A0522D; margin-top: 20px;">Evaluation Results</h5>
  <p style="margin-bottom: 1em;">
    We evaluated six state-of-the-art models: o1, GPT-4o, GPT-4o-mini, Gemini 2.5 Pro, Gemini 2.0 Flash, and Gemini 2.0 Flash Lite. Key findings:
  </p>
  <ul style="padding-left: 22px;">
    <li><strong>Impact of hop depth:</strong> All models exhibit consistent performance degradation as hop depth increases. On average, accuracy drops roughly 12 points from 1-hop to 4-hop at 64k context length.</li>
    <li><strong>Impact of context length:</strong> Longer contexts also lead to reduced accuracy, though the effect is milder than that of hop count. Across models, 1-hop performance drops about 5 points when moving from 64k to 128k contexts.</li>
    <li><strong>No model maintains strong performance</strong> on the hardest tasks (4-hop at 128k), where even top models dip below 80% accuracy.</li>
  </ul>
  <p style="margin-bottom: 1em;">
    These results highlight that simply increasing context window size isn't enough‚Äîrobust multi-hop reasoning remains a key challenge for LLMs, even at the frontier of model capabilities.
  </p>
</div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <p class="copyright text-muted">NovelHopQA ¬© 2025 Algoverse AI Research</p>
            <div class="template-credit-fixed">
              <p class="small text-muted">Template adapted from <a href="https://github.com/bird-bench/bird-bench.github.io" target="_blank">bird-bench</a></p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <style>
      .template-credit-fixed {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 9999;
        background: rgba(255,255,255,0.9);
        padding: 6px 12px;
        border-radius: 6px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
      }
      .template-credit-fixed p {
        margin: 0;
        font-size: 0.95em;
      }
    </style>

    <!-- Bootstrap core JavaScript -->
    <script src="./style/jquery.min.js"></script>
    <script src="./style/bootstrap.bundle.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="./style/clean-blog.min.js"></script>
    
    <!-- Tab functionality script -->
    <script>
      function showTab(tabId) {
        // Hide all tab content
        document.querySelectorAll('.tab-pane').forEach(function(tab) {
          tab.classList.remove('show', 'active');
        });
        // Remove active class from all tabs
        document.querySelectorAll('#leaderboard-tabs .nav-link').forEach(function(tab) {
          tab.classList.remove('active');
        });
        // Show the selected tab content
        document.getElementById(tabId).classList.add('show', 'active');
        // Add active class to the clicked tab
        if (tabId === 'accuracy-content') {
          document.getElementById('accuracy-tab').classList.add('active');
          localStorage.setItem('endive-selected-tab', 'accuracy-content');
        } else if (tabId === 'paper-content') {
          document.getElementById('paper-tab').classList.add('active');
          localStorage.setItem('endive-selected-tab', 'paper-content');
        }
      }
      // On page load, restore last selected tab
      window.addEventListener('DOMContentLoaded', function() {
        var lastTab = localStorage.getItem('endive-selected-tab');
        if (lastTab === 'paper-content') {
          showTab('paper-content');
        } else {
          showTab('accuracy-content');
        }
      });
    </script>
  </body>
</html>
